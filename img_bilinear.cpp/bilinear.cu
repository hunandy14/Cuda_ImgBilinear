/***************************************************************************************
Name :
Date : 2018/01/08
By   : CharlotteHonG
Final: 2018/01/08
***************************************************************************************/
#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include <iostream>
#include <vector>
using namespace std;

#include "CudaMem\CudaMem.cuh"
#include "timer\timer.hpp"

#define BLOCK_DIM 16

__host__ __device__
inline static float bilinearRead(const float* img, 
	size_t width, float y, float x) // 線性取值
{
	// 獲取鄰點(不能用 1+)
	size_t x0 = floor(x);
	size_t x1 = ceil(x);
	size_t y0 = floor(y);
	size_t y1 = ceil(y);
	// 獲取比例(只能用 1-)
	float dx1 = x - x0;
	float dx2 = 1 - dx1;
	float dy1 = y - y0;
	float dy2 = 1 - dy1;
	// 獲取點
	const float& A = img[y0*width + x0];
	const float& B = img[y0*width + x1];
	const float& C = img[y1*width + x0];
	const float& D = img[y1*width + x1];
	// 乘出比例(要交叉)
	float AB = A*dx2 + B*dx1;
	float CD = C*dx2 + D*dx1;
	float X = AB*dy2 + CD*dy1;
	return X;
}
//======================================================================================
// 宣告GPU紋理變數(只能放全域)
texture<float, 2, cudaReadModeElementType> rT;
// 紋理線性取值核心
__global__ void biliner_texture_kernel(float* dst, int srcW, int srcH, float ratio) {
	int idxX = blockIdx.x * blockDim.x + threadIdx.x,
		idxY = blockIdx.y * blockDim.y + threadIdx.y;
	if(idxX < srcW*ratio && idxY < srcH*ratio) { // 會多跑一點點要擋掉
		float srcX = idxX / ratio;
		float srcY = idxY / ratio;
		size_t idx = (idxY*srcW*ratio + idxX);
		dst[idx] = tex2D(rT, srcX+0.5, srcY+0.5);
	}
}
// 紋理線性取值函式
#define AutoMem_Style
#ifdef AutoMem_Style
__host__ void biliner_texture_core(float *dst, const float* src,
	size_t dstW, size_t dstH, float ratio)
{
	Timer T; T.priSta = 1;
	// 設置GPU所需長度
	int srcSize = dstW*dstH;
	int dstSize = srcSize*ratio*ratio;

	// 宣告 texture2D陣列並綁定
	T.start();
	CudaMemArr<float> cuArray(src, dstW, dstH);
	cudaBindTextureToArray(rT, cuArray);
	T.print("  GPU new 紋理空間+複製");

	// 設置 插植模式and超出邊界補邊界
	rT.filterMode = cudaFilterModeLinear;
	rT.addressMode[0] = cudaAddressModeClamp;
	rT.addressMode[1] = cudaAddressModeClamp;

	// 要求GPU空間
	T.start();
	CudaData<float> gpu_dst(dstSize);
	T.print("  GPU new 一般空間");

	// 設置執行緒
	dim3 block(BLOCK_DIM, BLOCK_DIM);
	dim3 grid(ceil((float)dstW*ratio / BLOCK_DIM), ceil((float)dstH*ratio / BLOCK_DIM));
	T.start();
	biliner_texture_kernel <<< grid, block >> > (gpu_dst, dstW, dstH, ratio);
	T.print("  核心計算");

	// 取出GPU值
	T.start();
	gpu_dst.memcpyOut(dst, dstSize);
	T.print("  GPU 取出資料");
}

#else
__host__ void biliner_texture_core(float *dst, const float* src,
	size_t dstW, size_t dstH, float ratio)
{
	Timer T; T.priSta = 1;
	// 設置GPU所需長度
	int srcSize = dstW*dstH;
	int dstSize = srcSize*ratio*ratio;

	// 宣告 texture2D陣列並綁定
	T.start();
	cudaChannelFormatDesc chDesc = cudaCreateChannelDesc<float>();
	cudaArray* cuArray = nullptr;
	cudaMallocArray(&cuArray, &chDesc, dstW, dstH);
	cudaMemcpyToArray(cuArray, 0, 0, src, srcSize*sizeof(float), cudaMemcpyHostToDevice);
	cudaBindTextureToArray(rT, cuArray);
	T.print("  GPU new 紋理空間");

	// 設置 插植模式and超出邊界補邊界
	rT.filterMode = cudaFilterModeLinear;
	rT.addressMode[0] = cudaAddressModeClamp;
	rT.addressMode[1] = cudaAddressModeClamp;

	// 要求GPU空間
	T.start();
	float* gpu_dst = nullptr;
	cudaMalloc((void**)&gpu_dst, dstSize*sizeof(float));
	T.print("  GPU new 一般空間");

	// 設置執行緒
	dim3 block(BLOCK_DIM, BLOCK_DIM);
	dim3 grid(ceil((float)dstW*ratio / BLOCK_DIM), ceil((float)dstH*ratio / BLOCK_DIM));
	T.start();
	biliner_kernel << < grid, block >> > (gpu_dst, dstW, dstH, ratio);
	T.print("  核心計算");

	// 取出GPU值
	T.start();
	cudaMemcpy(dst, gpu_dst, dstSize*sizeof(float), cudaMemcpyDeviceToHost);
	T.print("  GPU 取出資料");

	// 釋放GPU記憶體
	cudaUnbindTexture(rT);
	cudaFreeArray(cuArray);
	cudaFree(gpu_dst);
}
#endif // AutoMem_Style

// 紋理線性取值函式 vector 轉介介面
__host__ double biliner_texture(vector<float>& dst, const vector<float>& src,
	size_t width, size_t height, float ratio)
{
	Timer T; T.priSta = 1;
	T.start();
	dst.resize(width*ratio * height*ratio);
	T.print(" CPU new 儲存空間");
	T.start();
	biliner_texture_core(dst.data(), src.data(), width, height, ratio);
	T.print(" GPU 全部");
	return T;
}



//======================================================================================
// 共享記憶體線性取值核心
__global__ void biliner_share_kernel(float* dst, const float* src, int srcW, int srcH, float ratio) {
	int i = blockIdx.x * blockDim.x + threadIdx.x;
	int j = blockIdx.y * blockDim.y + threadIdx.y;
	int newH = (int)(floor(srcH * ratio));
	int newW = (int)(floor(srcW * ratio));
	if(i < srcW*ratio && j < srcH*ratio) { // 會多跑一點點要擋掉
		// 調整對齊
		float srcY, srcX;
		if (ratio < 1) {
			srcY = ((j+0.5f)/ratio) - 0.5;
			srcX = ((i+0.5f)/ratio) - 0.5;
		} else {
			srcY = j * (srcH-1.f) / (newH-1.f);
			srcX = i * (srcW -1.f) / (newW-1.f);
		}
		// 獲取插補值
		dst[j*newW + i] = bilinearRead(src, srcW, srcY, srcX);
	}
}
// 共享記憶體線性取值函式
__host__ void biliner_share_core(float *dst, const float* src,
	size_t srcW, size_t srcH, float ratio)
{
	Timer T; T.priSta = 1;
	// 設置GPU所需長度
	int srcSize = srcW*srcH;
	int dstSize = srcSize*ratio*ratio;

	// 要求GPU空間
	T.start();
	CudaData<float> gpu_src(srcSize);
	T.print("  GPU new 空間1");
	T.start();
	CudaData<float> gpu_dst(dstSize);
	T.print("  GPU new 空間2");
	// 複製到GPU
	T.start();
	gpu_src.memcpyIn(src, srcSize);
	T.print("  GPU 複製");

	// 設置執行緒
	dim3 block(BLOCK_DIM, BLOCK_DIM);
	dim3 grid(ceil((float)srcW*ratio / BLOCK_DIM), ceil((float)srcH*ratio / BLOCK_DIM));
	T.start();
	biliner_share_kernel <<< grid, block >> > (gpu_dst, gpu_src, srcW, srcH, ratio);
	T.print("  核心計算");

	// 取出GPU值
	T.start();
	gpu_dst.memcpyOut(dst, dstSize);
	T.print("  GPU 取出資料");

	// 釋放GPU空間
	T.start();
	gpu_src.~CudaData();
	gpu_dst.~CudaData();
	T.print("  GPU 釋放空間");
}

// 共享記憶體線性取值函式 vector 轉介介面
__host__ double biliner_share(vector<float>& dst, const vector<float>& src,
	size_t width, size_t height, float ratio)
{
	Timer T; T.priSta = 1;
	T.start();
	dst.resize(width*ratio * height*ratio);
	T.print(" CPU new 儲存空間");
	T.start();
	biliner_share_core(dst.data(), src.data(), width, height, ratio);
	T.print(" GPU 全部");
	return T;
}



//======================================================================================
__host__ void biliner_CPU_core(vector<float>& img, const vector<float>& img_ori, 
	size_t width, size_t height, float Ratio)
{
	int newH = static_cast<int>(floor(height * Ratio));
	int newW = static_cast<int>(floor(width  * Ratio));
	img.resize(newH*newW);
	// 跑新圖座標
	for (int j = 0; j < newH; ++j) {
		for (int i = 0; i < newW; ++i) {
			// 調整對齊
			float srcY, srcX;
			if (Ratio < 1) {
				srcY = ((j+0.5f)/Ratio) - 0.5;
				srcX = ((i+0.5f)/Ratio) - 0.5;
			} else {
				srcY = j * (height-1.f) / (newH-1.f);
				srcX = i * (width -1.f) / (newW-1.f);
			}
			// 獲取插補值
			img[j*newW + i] = bilinearRead(img_ori.data(), width, srcY, srcX);
		}
	}
}
__host__ double biliner_CPU(vector<float>& dst, const vector<float>& src,
	size_t width, size_t height, float ratio)
{
	Timer T; T.priSta = 1;
	T.start();
	dst.resize(width*ratio * height*ratio);
	T.print(" CPU new 儲存空間");
	T.start();
	biliner_CPU_core(dst, src, width, height, ratio);
	T.print(" CPU 全部");
	return T;
}
//======================================================================================


